{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e07d278e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0bf2717",
   "metadata": {},
   "outputs": [],
   "source": [
    "CrysDatPath = \"/home/sohamc2/HEA_FCC/CrysDat/\"\n",
    "DataPath = \"/home/sohamc2/HEA_FCC/MDMC/ML_runs/DataSets/\"\n",
    "ModulePath = \"/home/sohamc2/VKMC/SymNetworkRuns/CE_Symmetry/Symm_Network/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654c05c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "RunPath = os.getcwd() + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46f39224",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GCNetRun import Load_Data, Load_crysDats, makeComputeData, makeProdTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f51db00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as pt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import h5py\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from SymmLayers import GConv, R3Conv, R3ConvSites, GAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88b9c993",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNet(nn.Module):\n",
    "    def __init__(self, GnnPerms, gdiags, NNsites, SitesToShells,\n",
    "                dim, N_ngb, NSpec, mean=0.0, std=0.1, b=1.0, nl=3):\n",
    "        \n",
    "        super().__init__()\n",
    "        modules = []\n",
    "        modules += [GConv(NSpec, 8, GnnPerms, NNsites, N_ngb, mean=mean, std=std), \n",
    "                nn.Softplus(beta=b), GAvg()]\n",
    "\n",
    "        for i in range(nl):\n",
    "            modules += [GConv(8, 8, GnnPerms, NNsites, N_ngb, mean=mean, std=std), \n",
    "                    nn.Softplus(beta=b), GAvg()]\n",
    "\n",
    "        modules += [GConv(8, 1, GnnPerms, NNsites, N_ngb, mean=mean, std=std), \n",
    "                nn.Softplus(beta=b), GAvg()]\n",
    "\n",
    "        modules += [R3ConvSites(SitesToShells, GnnPerms, gdiags, NNsites, N_ngb, \n",
    "            dim, mean=mean, std=std)]\n",
    "        \n",
    "        self.net = nn.Sequential(*modules)\n",
    "    \n",
    "    def forward(self, InState):\n",
    "        y = self.net(InState)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f7eaff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## Write the training function\"\"\"\n",
    "def Train(dirPath, State1_Occs, State2_Occs, OnSites_st1, OnSites_st2,\n",
    "          y1Target, y2Target, SpecsToTrain, VacSpec, start_ep, end_ep,\n",
    "          interval, N_train, gNet, lRate=0.001, scratch_if_no_init=True):\n",
    "    \n",
    "    Ndim = disps.shape[2]\n",
    "    N_batch = 128\n",
    "    # Convert compute data to pytorch tensors\n",
    "    state1Data = pt.tensor(State1_Occs[:N_train]).double()\n",
    "    state2Data = pt.tensor(State2_Occs[:N_train]).double()\n",
    "    y1TargetData = pt.tensor(y1Target).double().to(device)\n",
    "    y2TargetData = pt.tensor(y2Target).double().to(device)\n",
    "\n",
    "    On_st1 = None\n",
    "    On_st2 = None   \n",
    "    if SpecsToTrain == [VacSpec]:\n",
    "        assert OnSites_st1 == OnSites_st2 == None\n",
    "        print(\"Training on Vacancy\".format(SpecsToTrain))\n",
    "    else:\n",
    "        print(\"Training Species : {}\".format(SpecsToTrain)) \n",
    "        On_st1 = makeProdTensor(OnSites_st1[:N_train], Ndim).long()\n",
    "        On_st2 = makeProdTensor(OnSites_st2[:N_train], Ndim).long()\n",
    "    \n",
    "    try:\n",
    "        gNet.load_state_dict(pt.load(dirPath + \"/ep_{1}.pt\".format(T, start_ep)))\n",
    "        print(\"Starting from epoch {}\".format(start_ep), flush=True)\n",
    "    except:\n",
    "        if scratch_if_no_init:\n",
    "            print(\"No Network found. Starting from scratch\", flush=True)\n",
    "        else:\n",
    "            raise ValueError(\"No saved network found in {} at epoch {}\".format(dirPath, start_ep))\n",
    "    \n",
    "    optimizer = pt.optim.Adam(gNet.parameters(), lr=lRate, weight_decay=0.0005)\n",
    "    print(\"Starting Training loop\") \n",
    "    for epoch in tqdm(range(start_ep, end_ep + 1), position=0, leave=True):\n",
    "        \n",
    "        ## checkpoint\n",
    "        if epoch%interval==0:\n",
    "            pt.save(gNet.state_dict(), dirPath + \"/ep_{1}.pt\".format(T, epoch))\n",
    "            \n",
    "        for batch in range(0, N_train, N_batch):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            end = min(batch + N_batch, N_train)\n",
    "\n",
    "            state1Batch = state1Data[batch : end].to(device)\n",
    "            state2Batch = state2Data[batch : end].to(device)\n",
    "            \n",
    "            y1_target_Batch = y1TargetData[batch : end]\n",
    "            y2_target_Batch = y2TargetData[batch : end]\n",
    "            \n",
    "            y1 = gNet(state1Batch)\n",
    "            y2 = gNet(state2Batch)\n",
    "            \n",
    "            # sum up everything except the vacancy site\n",
    "            if SpecsToTrain==[VacSpec]:\n",
    "                y1 = -pt.sum(y1[:, :, 1:], dim=2)\n",
    "                y2 = -pt.sum(y2[:, :, 1:], dim=2)\n",
    "            \n",
    "            else:\n",
    "                On_st1Batch = On_st1[batch : end].to(device)\n",
    "                On_st2Batch = On_st2[batch : end].to(device)\n",
    "                y1 = pt.sum(y1*On_st1Batch, dim=2)\n",
    "                y2 = pt.sum(y2*On_st2Batch, dim=2)\n",
    "\n",
    "            loss1 = pt.sum(pt.norm((y1_target_Batch - y1), dim=1)**2)\n",
    "            loss2 = pt.sum(pt.norm((y2_target_Batch - y2), dim=1)**2)\n",
    "            loss = (loss1 + loss2)/(2.0*(end - batch))\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16e775c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluate(dirPath, State1_Occs, State2_Occs, OnSites_st1, OnSites_st2,\n",
    "             y1Target, y2Target, SpecsToTrain, VacSpec,\n",
    "             start_ep, end_ep, interval, N_train, gNet):\n",
    "    \n",
    "    Ndim = disps.shape[2]\n",
    "    N_batch = 512\n",
    "    # Convert compute data to pytorch tensors\n",
    "    state1Data = pt.tensor(State1_Occs).double()\n",
    "    state2Data = pt.tensor(State2_Occs).double()\n",
    "    y1TargetData = pt.tensor(y1Target).double().to(device)\n",
    "    y2TargetData = pt.tensor(y2Target).double().to(device)\n",
    "\n",
    "    Nsamples = state1Data.shape[0]\n",
    "\n",
    "    print(\"Evaluating species: {}, Vacancy label: {}\".format(SpecsToTrain, VacSpec))\n",
    "    print(\"Sample Jumps: {}, Training: {}, Validation: {}\".format(Nsamples, N_train, Nsamples-N_train))\n",
    "    print(\"Evaluating with networks at: {}\".format(dirPath))\n",
    "    On_st1 = None\n",
    "    On_st2 = None\n",
    "    \n",
    "    if SpecsToTrain == [VacSpec]:\n",
    "        assert OnSites_st1 == OnSites_st2 == None\n",
    "    else:\n",
    "        On_st1 = makeProdTensor(OnSites_st1, Ndim).long()\n",
    "        On_st2 = makeProdTensor(OnSites_st2, Ndim).long()\n",
    "\n",
    "    def compute(startSample, endSample):\n",
    "        diff_epochs = []\n",
    "        with pt.no_grad():\n",
    "            for epoch in tqdm(range(start_ep, end_ep + 1, interval), position=0, leave=True):\n",
    "                ## load checkpoint\n",
    "                gNet.load_state_dict(pt.load(dirPath + \"/ep_{1}.pt\".format(epoch), map_location=device))\n",
    "                loss = 0 \n",
    "                for batch in range(startSample, endSample, N_batch):\n",
    "                    end = min(batch + N_batch, endSample)\n",
    "\n",
    "                    state1Batch = state1Data[batch : end].to(device)\n",
    "                    state2Batch = state2Data[batch : end].to(device)\n",
    "                    \n",
    "                    y1_target_Batch = y1TargetData[batch : end]\n",
    "                    y2_target_Batch = y2TargetData[batch : end]\n",
    "                    \n",
    "                    y1 = gNet(state1Batch)\n",
    "                    y2 = gNet(state2Batch)\n",
    "                    \n",
    "                    # sum up everything except the vacancy site if vacancy is indicated\n",
    "                    if SpecsToTrain==[VacSpec]:\n",
    "                        y1 = -pt.sum(y1[:, :, 1:], dim=2)\n",
    "                        y2 = -pt.sum(y2[:, :, 1:], dim=2)\n",
    "                    \n",
    "                    else:\n",
    "                        On_st1Batch = On_st1[batch : end].to(device)\n",
    "                        On_st2Batch = On_st2[batch : end].to(device)\n",
    "                        y1 = pt.sum(y1*On_st1Batch, dim=2)\n",
    "                        y2 = pt.sum(y2*On_st2Batch, dim=2)\n",
    "\n",
    "                    loss1 = pt.sum(pt.norm((y1_target_Batch - y1), dim=1)**2)\n",
    "                    loss2 = pt.sum(pt.norm((y2_target_Batch - y2), dim=1)**2)\n",
    "                    loss += (loss1 + loss2).item()\n",
    "                    \n",
    "                diff_epochs.append(loss)\n",
    "\n",
    "        return np.array(diff_epochs)\n",
    "    \n",
    "    train_diff = compute(0, N_train)\n",
    "    test_diff = compute(N_train, Nsamples)\n",
    "\n",
    "    return train_diff/(2.0*N_train), test_diff/(2.0*(Nsamples - N_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f8b4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "   def Gather_Y(dirPath, State1_Occs, State2_Occs,\n",
    "                OnSites_st1, OnSites_st2, SpecsToTrain,\n",
    "                VacSpec, epoch, gNet, Ndim):\n",
    "    \n",
    "    N_batch = 256\n",
    "    # Convert compute data to pytorch tensors\n",
    "    state1Data = pt.tensor(State1_Occs).double()\n",
    "    Nsamples = state1Data.shape[0]\n",
    "    state2Data = pt.tensor(State2_Occs).double()\n",
    "    On_st1 = None\n",
    "    On_st2 = None \n",
    "    \n",
    "    if SpecsToTrain == [VacSpec]:\n",
    "        assert OnSites_st1 == OnSites_st2 == None\n",
    "    else:\n",
    "        On_st1 = makeProdTensor(OnSites_st1, Ndim).long()\n",
    "        On_st2 = makeProdTensor(OnSites_st2, Ndim).long()\n",
    "\n",
    "    y1Vecs = np.zeros((Nsamples, 3))\n",
    "    y2Vecs = np.zeros((Nsamples, 3))\n",
    "\n",
    "    print(\"Evaluating network on species: {}, Vacancy label: {}\".format(SpecsToTrain, VacSpec))\n",
    "    print(\"Network: {}\".format(dirPath) + \"/ep_{1}.pt\".format(T, epoch))\n",
    "    with pt.no_grad():\n",
    "        ## load checkpoint\n",
    "        gNet.load_state_dict(pt.load(dirPath + \"/ep_{1}.pt\".format(epoch), map_location=device))\n",
    "                \n",
    "        for batch in tqdm(range(0, Nsamples, N_batch), position=0, leave=True):\n",
    "            end = min(batch + N_batch, Nsamples)\n",
    "\n",
    "            state1Batch = state1Data[batch : end].to(device)\n",
    "            state2Batch = state2Data[batch : end].to(device)\n",
    "            \n",
    "            y1 = gNet(state1Batch)\n",
    "            y2 = gNet(state2Batch)\n",
    "            \n",
    "            # sum up everything except the vacancy site if vacancy is indicated\n",
    "            if SpecsToTrain == [VacSpec]:\n",
    "                y1 = -pt.sum(y1[:, :, 1:], dim=2)\n",
    "                y2 = -pt.sum(y2[:, :, 1:], dim=2)\n",
    "            \n",
    "            else:\n",
    "                On_st1Batch = On_st1[batch : end].to(device)\n",
    "                On_st2Batch = On_st2[batch : end].to(device)\n",
    "                y1 = pt.sum(y1*On_st1Batch, dim=2)\n",
    "                y2 = pt.sum(y2*On_st2Batch, dim=2)\n",
    "            \n",
    "            y1Vecs[batch : end] = y1.cpu().numpy()\n",
    "            y2Vecs[batch : end] = y2.cpu().numpy()\n",
    "\n",
    "    return y1Vecs, y2Vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b3a741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    print(\"Running at : \"+ RunPath)\n",
    "\n",
    "    # Get run parameters\n",
    "    count=1\n",
    "    FileName = args[count] # Name of data file to train on\n",
    "    count += 1\n",
    "    \n",
    "    Jac_iter = int(args[count]) # target jacobian iteration to learn vectors from\n",
    "    count += 1\n",
    "    \n",
    "    Mode = args[count] # \"train\" mode or \"eval\" mode or \"getY\" mode\n",
    "    count += 1\n",
    "\n",
    "    nLayers = int(args[count])\n",
    "    count += 1\n",
    "    \n",
    "    scratch_if_no_init = bool(int(args[count]))\n",
    "    count += 1\n",
    "    \n",
    "    T_data = int(args[count]) # temperature to load data from\n",
    "    # Note : for binary random alloys, this should is the training composition instead of temperature\n",
    "    count += 1\n",
    "    \n",
    "    start_ep = int(args[count])\n",
    "    count += 1\n",
    "    \n",
    "    end_ep = int(args[count])\n",
    "    count += 1\n",
    "    \n",
    "    specTrain = args[count] # which species to train collectively: eg - 123 for species 1, 2 and 3\n",
    "    # The entry is order independent as it is sorted later\n",
    "    count += 1\n",
    "    \n",
    "    VacSpec = int(args[count]) # integer label for vacancy species\n",
    "    count += 1\n",
    "    \n",
    "    N_train = int(args[count]) # How many INITIAL STATES to consider for training\n",
    "    count += 1\n",
    "    \n",
    "    interval = int(args[count]) # for train mode, interval to save and for eval mode, interval to load\n",
    "    count += 1\n",
    "    \n",
    "    learning_Rate = float(args[count]) if len(args)==count+1 else 0.001\n",
    "        \n",
    "    if Mode == \"train\" or Mode == \"eval\":\n",
    "        AllJumps = False # whether to consider all jumps out of the samples or just stochastically selected one\n",
    "    elif Mode == \"getY\":\n",
    "        AllJumps = True\n",
    "        \n",
    "    # Load data\n",
    "    state1List, state2List, dispList, rateList, AllJumpRates, jmpSelects = Load_Data(FileName)\n",
    "    \n",
    "    specs = np.unique(state1List[0])\n",
    "    NSpec = specs.shape[0] - 1\n",
    "    Nsites = state1List.shape[1]\n",
    "     \n",
    "    specsToTrain = [int(specTrain[i]) for i in range(len(specTrain))]\n",
    "    specsToTrain = sorted(specsToTrain)\n",
    "    \n",
    "    direcString=\"\"\n",
    "    if specsToTrain == [VacSpec]:\n",
    "        direcString = \"vac\"\n",
    "    else:\n",
    "        for spec in specsToTrain:\n",
    "            direcString += \"{}\".format(spec)\n",
    "\n",
    "    # Load target jacobian data\n",
    "    y1Target = np.load(\"y1_{}\".format(T)+\"_\"+direcString+\"jac_{}.npy\".format(Jac_iter))\n",
    "    y2Target = np.load(\"y2_{}\".format(T)+\"_\"+direcString+\"jac_{}.npy\".format(Jac_iter))\n",
    "    \n",
    "    dirNameNets = \"ep_T_{0}_jac_{1}_n{2}c8\".format(T_data, direcString, nLayers)\n",
    "    if Mode == \"eval\" or Mode == \"getY\":\n",
    "        prepo = \"saved at\"\n",
    "    \n",
    "    elif Mode == \"train\":\n",
    "        prepo = \"saving in\"\n",
    "\n",
    "    # check if a run directory exists\n",
    "    dirPath = RunPath + dirNameNets\n",
    "    exists = os.path.isdir(dirPath)\n",
    "    \n",
    "    if not exists:\n",
    "        if scratch_if_no_init == False:\n",
    "            raise FileNotFoundError(\"Target directory does not exist but looking for existing networks.\")\n",
    "        else:\n",
    "            if start_ep == 0:\n",
    "                os.mkdir(dirPath)\n",
    "            elif start_ep > 0:\n",
    "                raise FileNotFoundError(\"Training directory does not exist but start epoch greater than zero: {}\\ndirectory given: {}\".format(start_ep, dirPath))\n",
    "\n",
    "    print(\"Running in Mode {} with networks {} {}\".format(Mode, prepo, dirPath))\n",
    "    \n",
    "    # Load crystal parameters\n",
    "    GpermNNIdx, NNsiteList, siteShellIndices, GIndtoGDict, JumpNewSites, dxJumps = Load_crysDats()\n",
    "    N_ngb = NNsiteList.shape[0]\n",
    "    Nsites = NNsiteList.shape[1]\n",
    "    SitesToShells = pt.tensor(siteShellIndices).long().to(device)\n",
    "    GnnPerms = pt.tensor(GpermNNIdx).long().to(device)\n",
    "    NNsites = pt.tensor(NNsiteList).long().to(device)\n",
    "\n",
    "    Ng = GnnPerms.shape[0]\n",
    "    Ndim = dispList.shape[2]\n",
    "    gdiagsCpu = pt.zeros(Ng*Ndim, Ng*Ndim).double()\n",
    "    for gInd, gCart in GIndtoGDict.items():\n",
    "        rowStart = gInd * Ndim\n",
    "        rowEnd = (gInd + 1) * Ndim\n",
    "        gdiagsCpu[rowStart : rowEnd, rowStart : rowEnd] = pt.tensor(gCart)\n",
    "    gdiags = gdiagsCpu\n",
    "    \n",
    "    # Make a network to either train from scratch or load saved state into\n",
    "    gNet = GCNet(GnnPerms, gdiags, NNsites, SitesToShells, Ndim, N_ngb, NSpec,\n",
    "            mean=0.02, std=0.2, b=1.0, nl=nLayers).double().to(device)\n",
    "        \n",
    "    # Call MakeComputeData here\n",
    "    State1_Occs, State2_Occs, _, _, OnSites_state1, OnSites_state2 =\\\n",
    "    makeComputeData(state1List, state2List, dispList, specsToTrain, VacSpec, \n",
    "                    rateList, AllJumpRates, JumpNewSites, dxJumps, NNsiteList,\n",
    "                    N_train, AllJumps=AllJumps)\n",
    "    print(\"Done Creating occupancy tensors\")\n",
    "    \n",
    "    # Call Training or evaluating or y-gathering function here\n",
    "    if Mode == \"train\":\n",
    "        Train(dirPath, State1_Occs, State2_Occs, OnSites_state1, OnSites_state2,\n",
    "              y1Target, y2Target, specsToTrain, VacSpec, start_ep, end_ep, interval, N_train, \n",
    "              gNet, lRate=learning_Rate, scratch_if_no_init=scratch_if_no_init)\n",
    "\n",
    "    elif Mode == \"eval\":\n",
    "        \n",
    "        train_diff, valid_diff = Evaluate(dirPath, State1_Occs, State2_Occs,\n",
    "                OnSites_state1, OnSites_state2, y1Target, y2Target,\n",
    "                specsToTrain, VacSpec, start_ep, end_ep,\n",
    "                interval, N_train, gNet)\n",
    "        \n",
    "        np.save(\"tr_{3}_{0}_jac_{1}_n{2}c8_.npy\".format(T_data, Jac_iter, nLayers, direcString),\n",
    "                train_diff)\n",
    "        \n",
    "        np.save(\"val_{3}_{0}_jac_{1}_n{2}c8_.npy\".format(T_data, Jac_iter, nLayers, direcString),\n",
    "                valid_diff)\n",
    "        \n",
    "    elif Mode == \"getY\":\n",
    "        assert AllJumps\n",
    "        y1Vecs, y2Vecs = Gather_Y(dirPath, State1_Occs, State2_Occs,\n",
    "                                  OnSites_state1, OnSites_state2, specsToTrain,\n",
    "                                  VacSpec, start_ep, gNet, Ndim)\n",
    "        \n",
    "        np.save(\"y1_{3}_{0}_jac{1}_n{2}c8.npy\".format(T_data, Jac_iter, nLayers,\n",
    "                                                      direcString), y1Vecs)\n",
    "        np.save(\"y2_{3}_{0}_jac{1}_n{2}c8.npy\".format(T_data, Jac_iter, nLayers,\n",
    "                                                      direcString), y2Vecs)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(list(sys.argv))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-Soham_pt_1.7]",
   "language": "python",
   "name": "conda-env-.conda-Soham_pt_1.7-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
