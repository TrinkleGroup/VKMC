{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Numba_GConv.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyON5FrIuyHtywdb2EjIGeTN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sohamch/VKMC/blob/SymmNets/Lattice_Gas/CE_Symmetry/Numba_Cuda/Numba_GConv.ipynb/Numba_GConv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSaJJD1KHq4M"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "from numba import cuda, jit, float32, float64, int64, uint8, int16"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw5DCJjSIdYS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "468a926b-a988-4af3-ebf8-b2f305d8ec7a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xW6pzhYIgho"
      },
      "source": [
        "FP = \"/content/drive/My Drive/Colab/Numba_Cuda/GConv/\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xScrwF0oI-if"
      },
      "source": [
        "NsitesMax = 1024\n",
        "NChMax = 100\n",
        "NngbMax = 13 # maximum for close packed structs +1 for the site itself     \n",
        "NChSitesMax = NChMax*NngbMax                                               "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SngK_IiXLoZU"
      },
      "source": [
        "# write device function for softplus\n",
        "@cuda.jit(device=True)\n",
        "def softPlus(x, beta, threshold):\n",
        "    if x < -threshold:\n",
        "        return 0.0\n",
        "    elif x > threshold:\n",
        "        return x\n",
        "    else:\n",
        "        return math.log(1.0 + math.exp(beta*x))/beta\n",
        "\n",
        "@cuda.jit(device=True)\n",
        "def gradSoftPlus(x, beta, threshold):\n",
        "    if x < -threshold:\n",
        "        return 0.0\n",
        "    elif x > threshold:\n",
        "        return 1.0\n",
        "    else:\n",
        "        return 1./(1.0 + math.exp(-beta*x))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rc9v2r5pdU8P"
      },
      "source": [
        "@cuda.jit\n",
        "def Gconv(InputImage, Psi, OutImage, SiteNeighbors, GnnPerms,\n",
        "          Nsites, NInCh, NOutCh, N_ngb, Ng,\n",
        "          sp_beta, sp_threshold):\n",
        "    # first get locations\n",
        "    ty = cuda.threadIdx.y\n",
        "    bx, by, bz = cuda.blockIdx.x, cuda.blockIdx.y, cuda.blockIdx.z\n",
        "\n",
        "    bSizeX, bSizeY, bSizeZ = cuda.blockDim.x, cuda.blockDim.y, cuda.blockDim.z\n",
        "\n",
        "    # Get the necessary output indices\n",
        "    batchInd = bx # which sample the thread is working with\n",
        "    outCh = (by*bSizeY + ty)//Nsites  # thread's output channel\n",
        "    siteInd = (by*bSizeY + ty)%Nsites # which site the conv is over\n",
        "    gInd = bz  # which group operation the thread is handling\n",
        "\n",
        "    # Get the neighborhood of the current site\n",
        "    # in the thread's local memory\n",
        "    NgbIndices = cuda.local.array(shape=(NngbMax,), dtype=int64)\n",
        "    for ngb in range(N_ngb):\n",
        "        NgbIndices[ngb] = SiteNeighbors[siteInd, ngb]\n",
        "\n",
        "    # create the shared arrays to store filters and input elements\n",
        "    InChannel = cuda.shared.array(shape=(NsitesMax,), dtype=float64)\n",
        "    Filter = cuda.shared.array(shape=(NChSitesMax,), dtype=float64)\n",
        "\n",
        "    # Store the Group rotations of nns into shared memory\n",
        "    gnnRotShared = cuda.local.array(shape=(NngbMax,), dtype=uint8)\n",
        "    if ty < N_ngb:\n",
        "        gnnRotShared[ty] = GnnPerms[gInd, ty]\n",
        "\n",
        "    linSum = 0.\n",
        "    for inCh in range(NInCh):\n",
        "        # First read the input channel into shared memory\n",
        "        for sweep in range(Nsites//bSizeY + 1):\n",
        "            threadSiteInd = sweep*bSizeY + ty\n",
        "            if threadSiteInd < Nsites:\n",
        "                InChannel[threadSiteInd] = InputImage[batchInd, inCh, threadSiteInd]\n",
        "        \n",
        "        # Then read the filter for this input channel\n",
        "        # Apply Group permutation to it as well\n",
        "        for sweep in range((NOutCh*N_ngb)//bSizeY + 1):\n",
        "            threadElemInd = sweep*bSizeY + ty\n",
        "            if threadElemInd < NOutCh*N_ngb:\n",
        "                Filter[threadElemInd] = Psi[inCh, threadElemInd]\n",
        "        \n",
        "        # synchronize the block\n",
        "        cuda.syncthreads()\n",
        "\n",
        "        # Reading phase is done - now convolve\n",
        "        for ngb in range(N_ngb):\n",
        "            ngbSite = NgbIndices[ngb]\n",
        "            linSum += Filter[outCh*N_ngb + gnnRotShared[ngb]] * InChannel[ngbSite]\n",
        "    \n",
        "    nonLin = softPlus(linSum,sp_beta, sp_threshold)/Ng\n",
        "    # atomically sum out the group channel\n",
        "    cuda.atomic.add(OutImage, (batchInd, outCh, siteInd), nonLin)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSQDvKTqIOBM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e211eae5-fc01-4161-da69-4dd208e783fd"
      },
      "source": [
        "# load the data\n",
        "NNSites = np.load(FP + \"NNsites_sitewise.npy\").T\n",
        "GNNperms = np.load(FP + \"GroupNNpermutations.npy\")\n",
        "RtoSiteInd = np.load(FP + \"RtoSiteInd.npy\")\n",
        "SiteIndtoR = np.load(FP + \"SiteIndtoR.npy\")\n",
        "(Nsites, N_ngb) = NNSites.shape\n",
        "Ng = GNNperms.shape[0]\n",
        "print(N_ngb, Nsites, Ng)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9 512 48\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkg_6PjwKwfp"
      },
      "source": [
        "# # load the pickle files\n",
        "# import pickle\n",
        "# with open(FP + \"supercellBCC.pkl\", \"rb\") as fl:\n",
        "#     superBCC = pickle.load(fl)\n",
        "\n",
        "# with open(FP + \"GroupOpsIndices.pkl\", \"rb\") as fl:\n",
        "#     GIndices = pickle.load(fl)\n",
        "\n",
        "# with open(FP + \"jnetBCC.pkl\") as fl:\n",
        "#     jNetBCC = pickle.load(fl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBYKzC30LNim"
      },
      "source": [
        "# Create a random input and output image map\n",
        "Nsites = 512\n",
        "Nbatch = 512\n",
        "NchIn = 32\n",
        "NchOut = 16\n",
        "InImage = np.random.rand(Nbatch, NchIn, Nsites)\n",
        "OutImage = np.zeros((Nbatch, NchOut, Nsites))"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raX02dI6NgMu"
      },
      "source": [
        "# Now set up a random filter\n",
        "Psi = np.random.rand(NchIn, NchOut*N_ngb)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hr6YrpqWPVWT"
      },
      "source": [
        "ty = 512\n",
        "NbatchRun = 512\n",
        "bX = NbatchRun\n",
        "bY = int(np.ceil((NchOut*Nsites)/ty))\n",
        "bZ = Ng"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsJcgY8kpmJy",
        "outputId": "38ada25d-9083-41ae-abb7-4e9b1b730969"
      },
      "source": [
        "%%time\n",
        "d_input = cuda.to_device(InImage)\n",
        "d_output = cuda.to_device(OutImage)\n",
        "d_NNSites = cuda.to_device(NNSites)\n",
        "d_GNNperms = cuda.to_device(GNNperms)\n",
        "d_Psi = cuda.to_device(Psi)\n",
        "\n",
        "d_Nsites = cuda.to_device(Nsites)\n",
        "d_NchIn = cuda.to_device(NchIn)\n",
        "d_NchOut = cuda.to_device(NchOut)\n",
        "d_Nngb = cuda.to_device(N_ngb)\n",
        "d_ng = cuda.to_device(Ng)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 30.3 ms, sys: 3.67 ms, total: 33.9 ms\n",
            "Wall time: 35.8 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imbxB8JbpTta",
        "outputId": "4d65762f-9dd9-473a-b8f8-52229332d019"
      },
      "source": [
        "%%time\n",
        "Gconv[(bX, bY, bZ), (1, ty, 1)](d_input[:128], d_Psi, d_output, d_NNSites, d_GNNperms,\n",
        "          Nsites, NchIn, NchOut, N_ngb, Ng,\n",
        "          1.0, 20.0)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.19 ms, sys: 0 ns, total: 1.19 ms\n",
            "Wall time: 1.37 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKVR1HVL0jUz"
      },
      "source": [
        "# Copy the output to the host\n",
        "HostOut = d_output.copy_to_host()"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-7F58xiCwED"
      },
      "source": [
        "# Now let's do the conv explictly\n",
        "# We'll test randomly chosen samples for time considerations\n",
        "def softPlus(x, beta, threshold):\n",
        "    if x < -threshold:\n",
        "        return 0.0\n",
        "    elif x > threshold:\n",
        "        return x\n",
        "    else:\n",
        "        return math.log(1.0 + math.exp(beta*x))/beta\n",
        "\n",
        "# select a random sample\n",
        "sampInd = np.random.ranint(0, 512)\n",
        "outSamp = OutImage[sampInd].copy()\n",
        "for outCh in range(NchOut):\n",
        "    for siteInd in range(Nsite):\n",
        "\n",
        "        # Now go through the input channels\n",
        "        for g in range(gInd):\n",
        "            for inCh in range(NchIn):\n",
        "                for ngb in range(N_ngb):\n",
        "                    filt = Psi[inch, outCh*N_ngb + ]\n",
        "                "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}