{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Numba_GConv.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMEqxGvO5508rF97JkCBtLW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sohamch/VKMC/blob/SymmNets/Lattice_Gas/CE_Symmetry/Numba_Cuda/Numba_GConv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSaJJD1KHq4M"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "from numba import cuda, jit, float32, float64, int64, uint8, int16\n",
        "# import cupy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw5DCJjSIdYS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4d4b687-32e3-48b6-d330-4dc1af7d41ae"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xW6pzhYIgho"
      },
      "source": [
        "FP = \"/content/drive/My Drive/Colab/Numba_Cuda/GConv/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xScrwF0oI-if"
      },
      "source": [
        "NsitesMax = 1024\n",
        "NChMax = 100\n",
        "NngbMax = 13 # maximum for close packed structs +1 for the site itself     \n",
        "NChSitesMax = NChMax*NngbMax                                               "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SngK_IiXLoZU"
      },
      "source": [
        "# write device function for softplus\n",
        "@cuda.jit(device=True)\n",
        "def softPlus(x, beta, threshold):\n",
        "    if x < -threshold:\n",
        "        return 0.0\n",
        "    elif x > threshold:\n",
        "        return x\n",
        "    else:\n",
        "        return math.log(1.0 + math.exp(beta*x))/beta\n",
        "\n",
        "@cuda.jit(device=True)\n",
        "def gradSoftPlus(x, beta, threshold):\n",
        "    if x < -threshold:\n",
        "        return 0.0\n",
        "    elif x > threshold:\n",
        "        return 1.0\n",
        "    else:\n",
        "        return 1./(1.0 + math.exp(-beta*x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rc9v2r5pdU8P"
      },
      "source": [
        "# @cuda.jit\n",
        "# def Gcorr(InputImage, Psi, OutImage, OutF, SiteNeighbors, GnnPerms, N_array,\n",
        "#           sp_beta, sp_threshold):\n",
        "@cuda.jit\n",
        "def Gcorr(InputImage, Psi, OutImage, SiteNeighbors, GnnPerms, N_array,\n",
        "          sp_beta, sp_threshold):\n",
        "    # first get locations\n",
        "    ty = cuda.threadIdx.y\n",
        "    bx, by, bz = cuda.blockIdx.x, cuda.blockIdx.y, cuda.blockIdx.z\n",
        "\n",
        "    bSizeX, bSizeY, bSizeZ = cuda.blockDim.x, cuda.blockDim.y, cuda.blockDim.z\n",
        "\n",
        "    Nsites = N_array[0] \n",
        "    NInCh = N_array[1]\n",
        "    NOutCh = N_array[2]\n",
        "    N_ngb = N_array[3]\n",
        "    Ng = N_array[4]\n",
        "\n",
        "    # Get the necessary output indices\n",
        "    batchInd = bx # which sample the thread is working with\n",
        "    outCh = (by*bSizeY + ty)//Nsites  # thread's output channel\n",
        "    siteInd = (by*bSizeY + ty)%Nsites # which site the conv is over\n",
        "    gInd = bz  # which group operation the thread is handling\n",
        "\n",
        "    # Get the neighborhood of the current site\n",
        "    # in the thread's local memory\n",
        "    NgbIndices = cuda.local.array(shape=(NngbMax,), dtype=int64)\n",
        "    for ngb in range(N_ngb):\n",
        "        NgbIndices[ngb] = SiteNeighbors[siteInd, ngb]\n",
        "\n",
        "    # create the shared arrays to store filters and input elements\n",
        "    InChannel = cuda.shared.array(shape=(NsitesMax,), dtype=float64)\n",
        "    Filter = cuda.shared.array(shape=(NChSitesMax,), dtype=float64)\n",
        "\n",
        "    # Store the Group rotations of nns into shared memory\n",
        "    gnnRotShared = cuda.shared.array(shape=(NngbMax,), dtype=uint8)\n",
        "    if ty < N_ngb:\n",
        "        gnnRotShared[ty] = GnnPerms[gInd, ty]\n",
        "\n",
        "    linSum = 0.\n",
        "    for inCh in range(NInCh):\n",
        "        # First read the input channel into shared memory\n",
        "        for sweep in range(Nsites//bSizeY + 1):\n",
        "            threadSiteInd = sweep*bSizeY + ty\n",
        "            if threadSiteInd < Nsites:\n",
        "                InChannel[threadSiteInd] = InputImage[batchInd, inCh, threadSiteInd]\n",
        "        \n",
        "        # Then read the filter for this input channel\n",
        "        # Apply Group permutation to it as well\n",
        "        for sweep in range((NOutCh*N_ngb)//bSizeY + 1):\n",
        "            threadElemInd = sweep*bSizeY + ty\n",
        "            if threadElemInd < NOutCh*N_ngb:\n",
        "                Filter[threadElemInd] = Psi[inCh, threadElemInd]\n",
        "        \n",
        "        # synchronize the block\n",
        "        cuda.syncthreads()\n",
        "\n",
        "        # Reading phase is done - now convolve\n",
        "        for ngb in range(N_ngb):\n",
        "            ngbSite = NgbIndices[ngb]\n",
        "            linSum += Filter[outCh*N_ngb + gnnRotShared[ngb]] * InChannel[ngbSite]\n",
        "\n",
        "    # OutF[batchInd, outCh, gInd, siteInd] = linSum\n",
        "    nonLin = softPlus(linSum, sp_beta, sp_threshold)/Ng\n",
        "    # atomically sum out the group channel\n",
        "    cuda.atomic.add(OutImage, (batchInd, outCh, siteInd), nonLin)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIpgfeMP_Zzm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ox-yA2FZqnFE"
      },
      "source": [
        "@cuda.jit\n",
        "def GConvBack(dL_dOutImg, InImg, Psi, dL_dInImg, NbgSites, Narray,\n",
        "              sp_beta, sp_threshold):\n",
        "\n",
        "    ty = cuda.threadIdx.y\n",
        "    bSizeX, bSizeY, bSizeZ = cuda.blockIdx.x, cuda.blockIdx.y, cuda.blockIdx.z\n",
        "    \n",
        "    Nsites = N_array[0] \n",
        "    NInCh = N_array[1]\n",
        "    NOutCh = N_array[2]\n",
        "    N_ngb = N_array[3]\n",
        "    Ng = N_array[4]\n",
        "\n",
        "    # Get the necessary output indices\n",
        "    batchInd = bx # which sample the thread is working with\n",
        "    outCh = (by*bSizeY + ty)//Nsites  # thread's output channel\n",
        "    siteInd = (by*bSizeY + ty)%Nsites # which site the conv is over\n",
        "    gInd = bz  # which group operation the thread is handling\n",
        "\n",
        "    # First compute the linear correlation term\n",
        "    \n",
        "    # Get the neighborhood of the current site\n",
        "    # in the thread's local memory\n",
        "    NgbIndices = cuda.local.array(shape=(NngbMax,), dtype=int64)\n",
        "    for ngb in range(N_ngb):\n",
        "        NgbIndices[ngb] = SiteNeighbors[siteInd, ngb]\n",
        "\n",
        "    # create the shared arrays to store filters and input elements\n",
        "    InChannel = cuda.shared.array(shape=(NsitesMax,), dtype=float64)\n",
        "    Filter = cuda.shared.array(shape=(NChSitesMax,), dtype=float64)\n",
        "\n",
        "    # Store the Group rotations of nns into shared memory\n",
        "    gnnRotShared = cuda.shared.array(shape=(NngbMax,), dtype=uint8)\n",
        "    if ty < N_ngb:\n",
        "        gnnRotShared[ty] = GnnPerms[gInd, ty]\n",
        "\n",
        "    linSum = 0.\n",
        "    for inCh in range(NInCh):\n",
        "        # First read the input channel into shared memory\n",
        "        for sweep in range(Nsites//bSizeY + 1):\n",
        "            threadSiteInd = sweep*bSizeY + ty\n",
        "            if threadSiteInd < Nsites:\n",
        "                InChannel[threadSiteInd] = InImg[batchInd, inCh, threadSiteInd]\n",
        "        \n",
        "        # Then read the filter for this input channel\n",
        "        for sweep in range((NOutCh*N_ngb)//bSizeY + 1):\n",
        "            threadElemInd = sweep*bSizeY + ty\n",
        "            if threadElemInd < NOutCh*N_ngb:\n",
        "                Filter[threadElemInd] = Psi[inCh, threadElemInd]\n",
        "        \n",
        "        # synchronize the block\n",
        "        cuda.syncthreads()\n",
        "\n",
        "        # Reading phase is done - now convolve\n",
        "        for ngb in range(N_ngb):\n",
        "            ngbSite = NgbIndices[ngb]\n",
        "            linSum += Filter[outCh*N_ngb + gnnRotShared[ngb]] * InChannel[ngbSite]\n",
        "    \n",
        "    # once the linear sum for this layer is found, we need to\n",
        "    # add its contribution to the relevant components of the gradient\n",
        "    nonLinGrad = gradSoftPlus(linSum, sp_beta, sp_threshold)\n",
        "\n",
        "    for inCh in range(NInCh): # iterate over input channels\n",
        "        # Read the filter again for this input channel.\n",
        "        for sweep in range((NOutCh*N_ngb)//bSizeY + 1):\n",
        "            threadElemInd = sweep*bSizeY + ty\n",
        "            if threadElemInd < NOutCh*N_ngb:\n",
        "                Filter[threadElemInd] = Psi[inCh, threadElemInd]\n",
        "\n",
        "        for ngb in range(N_ngb): # iterate over nearest neighbors to write to\n",
        "            ngbSite = NgbIndices[ngb]\n",
        "            dL_dInImg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSQDvKTqIOBM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "397b0608-7562-4d83-f335-103cfdfd5603"
      },
      "source": [
        "# load the data\n",
        "NNSites = np.load(FP + \"NNsites_sitewise.npy\").T\n",
        "GNNperms = np.load(FP + \"GroupNNpermutations.npy\")\n",
        "RtoSiteInd = np.load(FP + \"RtoSiteInd.npy\")\n",
        "SiteIndtoR = np.load(FP + \"SiteIndtoR.npy\")\n",
        "(Nsites, N_ngb) = NNSites.shape\n",
        "Ng = GNNperms.shape[0]\n",
        "print(N_ngb, Nsites, Ng)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9 512 48\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkg_6PjwKwfp"
      },
      "source": [
        "# # load the pickle files\n",
        "# import pickle\n",
        "# with open(FP + \"supercellBCC.pkl\", \"rb\") as fl:\n",
        "#     superBCC = pickle.load(fl)\n",
        "\n",
        "# with open(FP + \"GroupOpsIndices.pkl\", \"rb\") as fl:\n",
        "#     GIndices = pickle.load(fl)\n",
        "\n",
        "# with open(FP + \"jnetBCC.pkl\") as fl:\n",
        "#     jNetBCC = pickle.load(fl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBYKzC30LNim"
      },
      "source": [
        "# Create a random input and output image map\n",
        "Nsites = 512\n",
        "Nbatch = 128\n",
        "NchIn = 1\n",
        "NchOut = 1\n",
        "InImage = np.random.rand(Nbatch, NchIn, Nsites)\n",
        "OutImage = np.zeros((Nbatch, NchOut, Nsites))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raX02dI6NgMu"
      },
      "source": [
        "# Now set up a random filter\n",
        "Psi = np.random.rand(NchIn, NchOut*N_ngb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hr6YrpqWPVWT"
      },
      "source": [
        "ty = 512\n",
        "NbatchRun = Nbatch\n",
        "bX = NbatchRun\n",
        "bY = int(np.ceil((NchOut*Nsites)/ty))\n",
        "bZ = Ng"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsJcgY8kpmJy",
        "outputId": "fd905c6c-fe06-467f-b0e3-9660a0860589"
      },
      "source": [
        "%%time\n",
        "d_input = cuda.to_device(InImage)\n",
        "d_NNSites = cuda.to_device(NNSites)\n",
        "d_GNNperms = cuda.to_device(GNNperms)\n",
        "d_Psi = cuda.to_device(Psi)\n",
        "\n",
        "N_array = np.array([Nsites, NchIn, NchOut, N_ngb, Ng])\n",
        "d_Narray = cuda.to_device(N_array)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 24.7 ms, sys: 192 ms, total: 217 ms\n",
            "Wall time: 276 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvEQYhzsJYm_"
      },
      "source": [
        "d_output = cuda.to_device(OutImage)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-GzRHMmJo4x"
      },
      "source": [
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imbxB8JbpTta",
        "outputId": "d62d7e33-8055-4def-9d46-1374289eca2a"
      },
      "source": [
        "Nrun = 1000\n",
        "start = time.time()\n",
        "for i in range(Nrun):\n",
        "    Gcorr[(bX, bY, bZ), (1, ty, 1)](d_input, d_Psi, d_output, d_NNSites, \n",
        "                                    d_GNNperms, d_Narray,\n",
        "                                    1.0, 20.0)\n",
        "print(\"Avg. time per run : {}\".format((time.time() - start)/Nrun))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Avg. time per run : 0.00041543340682983397\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKVR1HVL0jUz"
      },
      "source": [
        "# Copy the output to the host\n",
        "HostOut = d_output.copy_to_host()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-7F58xiCwED"
      },
      "source": [
        "# Now let's do the conv explictly\n",
        "# We'll test randomly chosen samples for time considerations\n",
        "def softPlusCPU(x, beta, threshold):\n",
        "    if x < -threshold:\n",
        "        return 0.0\n",
        "    elif x > threshold:\n",
        "        return x\n",
        "    else:\n",
        "        return math.log(1.0 + math.exp(beta*x))/beta\n",
        "\n",
        "# select a random sample\n",
        "sampInd = np.random.randint(0, NbatchRun)\n",
        "outSamp = OutImage[sampInd].copy()\n",
        "# outSampF = OutImageF[sampInd].copy()\n",
        "for outCh in range(NchOut):\n",
        "    for siteInd in range(Nsites):\n",
        "        # Now go through the input channels\n",
        "        gsum = 0.\n",
        "        for gInd in range(Ng):\n",
        "            linSum = 0.\n",
        "            for inCh in range(NchIn):\n",
        "                for ngb in range(N_ngb):\n",
        "                    filt = Psi[inCh, outCh*N_ngb + GNNperms[gInd, ngb]]\n",
        "                    linSum += filt * InImage[sampInd, inCh, NNSites[siteInd, ngb]]\n",
        "            \n",
        "            # outSampF[outCh, gInd, siteInd] = linSum\n",
        "\n",
        "            gsum += softPlusCPU(linSum, 1, 20)/Ng\n",
        "        \n",
        "        outSamp[outCh, siteInd] = gsum\n",
        "\n",
        "# assert np.allclose(HostF[sampInd], outSampF)\n",
        "assert np.allclose(HostOut[sampInd], outSamp)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}