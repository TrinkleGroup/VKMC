{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting KMC Data for Making Single-step Dataset\n",
    "In this notebook, we extract the data from our 2-step KMC runs (as shown in sample slurm script \"job_script_KMC.sb\"). We then save the data in an hdf5 file in a format that can be used in our machine learning and cluster expansion codes.\n",
    "\n",
    "This notebook also serves as a more hands-on insight into the outputs of the KMC code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "from scipy.constants import physical_constants\n",
    "kB = physical_constants[\"Boltzmann constant in eV/K\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onsager import crystal, supercell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load crystal data\n",
    "with h5py.File(\"../../CrysDat_FCC/CrystData.h5\", \"r\") as fl:\n",
    "    lattice = np.array(fl[\"Lattice_basis_vectors\"])\n",
    "    superlatt = np.array(fl[\"SuperLatt\"])\n",
    "    dxList = np.array(fl[\"dxList_1nn\"])\n",
    "    JumpNewSites = np.array(fl[\"JumpSiteIndexPermutation\"])\n",
    "    NNsites = np.array(fl[\"NNsiteList_sitewise\"])\n",
    "\n",
    "crys = crystal.Crystal.FCC(a0 = 1.0, chemistry=[\"A\"])\n",
    "assert np.allclose(lattice, crys.lattice)\n",
    "\n",
    "superFCC = supercell.ClusterSupercell(crys, superlatt)\n",
    "\n",
    "NNsites_vac = NNsites[1:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1073"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "['states_0_400', 'states_400_800', 'states_800_1200', 'states_1200_1600', 'states_1600_2000']\n",
      "2000\n",
      "['states_2000_2400', 'states_2400_2800', 'states_2800_3200', 'states_3200_3600', 'states_3600_4000']\n",
      "4000\n",
      "['states_4000_4400', 'states_4400_4800', 'states_4800_5200', 'states_5200_5600', 'states_5600_6000']\n",
      "6000\n",
      "['states_6000_6400', 'states_6400_6800', 'states_6800_7200', 'states_7200_7600', 'states_7600_8000']\n",
      "8000\n",
      "['states_8000_8400', 'states_8400_8800', 'states_8800_9200', 'states_9200_9600', 'states_9600_10000']\n",
      "10000\n",
      "['states_10000_10400', 'states_10400_10800', 'states_10800_11200', 'states_11200_11600', 'states_11600_12000']\n",
      "12000\n",
      "['states_12000_12400', 'states_12400_12800', 'states_12800_13200', 'states_13200_13600', 'states_13600_14000']\n",
      "14000\n",
      "['states_14000_14400', 'states_14400_14800', 'states_14800_15200', 'states_15200_15600', 'states_15600_16000']\n",
      "16000\n",
      "['states_16000_16400', 'states_16400_16800', 'states_16800_17200', 'states_17200_17600', 'states_17600_18000']\n",
      "18000\n",
      "['states_18000_18400', 'states_18400_18800', 'states_18800_19200', 'states_19200_19600', 'states_19600_20000']\n"
     ]
    }
   ],
   "source": [
    "# Make the intervals and subintervals\n",
    "intervalSize = 2000\n",
    "startSamps = [0, 2000, 4000, 6000, 8000,\n",
    "              10000, 12000, 14000, 16000, 18000]\n",
    "\n",
    "intervals = [\"0_2e3\", \"2e3_4e3\", \"4e3_6e3\", \"6e3_8e3\", \"8e3_10e3\",\n",
    "             \"10e3_12e3\", \"12e3_14e3\", \"14e3_16e3\", \"16e3_18e3\", \"18e3_20e3\"]\n",
    "\n",
    "SubIntervals = [[\"states_{}_{}\".format(x, x + 400) for x in range(st, st + 2000, 400)] for st in startSamps]\n",
    "\n",
    "for idx in range(len(startSamps)):\n",
    "    print(startSamps[idx])\n",
    "    print(SubIntervals[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nsamples: 20000\n",
      "0 400\n",
      "400 800\n",
      "800 1200\n",
      "1200 1600\n",
      "1600 2000\n",
      "2000 2400\n",
      "2400 2800\n",
      "2800 3200\n",
      "3200 3600\n",
      "3600 4000\n",
      "4000 4400\n",
      "4400 4800\n",
      "4800 5200\n",
      "5200 5600\n",
      "5600 6000\n",
      "6000 6400\n",
      "6400 6800\n",
      "6800 7200\n",
      "7200 7600\n",
      "7600 8000\n",
      "8000 8400\n",
      "8400 8800\n",
      "8800 9200\n",
      "9200 9600\n",
      "9600 10000\n",
      "10000 10400\n",
      "10400 10800\n",
      "10800 11200\n",
      "11200 11600\n",
      "11600 12000\n",
      "12000 12400\n",
      "12400 12800\n",
      "12800 13200\n",
      "13200 13600\n",
      "13600 14000\n",
      "14000 14400\n",
      "14400 14800\n",
      "14800 15200\n",
      "15200 15600\n",
      "15600 16000\n",
      "16000 16400\n",
      "16400 16800\n",
      "16800 17200\n",
      "17200 17600\n",
      "17600 18000\n",
      "18000 18400\n",
      "18400 18800\n",
      "18800 19200\n",
      "19200 19600\n",
      "19600 20000\n"
     ]
    }
   ],
   "source": [
    "# Load the initial states\n",
    "\n",
    "initStates = np.load(\"InitStates/statesAll_{0}.npy\".format(T))\n",
    "Nsamples = initStates.shape[0]\n",
    "print(\"Nsamples: {}\".format(Nsamples))\n",
    "\n",
    "NSpec = 6 # including the vacancy\n",
    "N_units = 8\n",
    "\n",
    "finalStates_UT = np.zeros_like(initStates) # these will not have vacancy at (0, 0, 0)\n",
    "finalStates = np.zeros_like(initStates) # these WILL have vacancy at (0, 0, 0)\n",
    "\n",
    "SpecDisps = np.zeros((initStates.shape[0], NSpec, 3)) # displacement of the species in step 1.\n",
    "SpecDisps_step2 = np.zeros((initStates.shape[0], NSpec, 3)) # displacement of the species in step 2.\n",
    "t_arr = np.zeros(initStates.shape[0]) # the time for step 1\n",
    "t_arr_step2 = np.zeros(initStates.shape[0]) # the time for step 2\n",
    "\n",
    "# Next, rates and barriers for the the 12 jumps out of the initial and final states of step 1.\n",
    "AllJumpRates_Init = np.zeros((initStates.shape[0], 12))\n",
    "AllJumpRates_Fin = np.zeros((initStates.shape[0], 12))\n",
    "\n",
    "AllJumpBarriers_Init = np.zeros((initStates.shape[0], 12))\n",
    "AllJumpBarriers_Fin = np.zeros((initStates.shape[0], 12))\n",
    "\n",
    "# random numbers to check for correctness\n",
    "randomNumbers = np.zeros(initStates.shape[0])\n",
    "JumpSelects = np.zeros(initStates.shape[0], dtype=np.int8)\n",
    "\n",
    "randomNumbers_step2 = np.zeros(initStates.shape[0])\n",
    "JumpSelects_step2 = np.zeros(initStates.shape[0], dtype=np.int8)\n",
    "\n",
    "# Now load and store all the states\n",
    "for intervalIdx in range(len(intervals)):\n",
    "    intervalRun = intervals[intervalIdx]\n",
    "    \n",
    "    subInts = SubIntervals[intervalIdx]\n",
    "    \n",
    "    startState = startSamps[intervalIdx]\n",
    "    \n",
    "    # print(intervalRun, startState)\n",
    "    for subIntRunIdx in range(len(subInts)):\n",
    "        subStart = startState + subIntRunIdx * 400\n",
    "        subEnd = subStart + 400\n",
    "        \n",
    "        # Load the data\n",
    "        # step 1\n",
    "        states_stored_step0 = np.load(\"{0}/{1}/states_{2}_{3}/states_step0_{0}.npy\".format(T, intervalRun,\n",
    "                                                                                           subStart, subEnd))\n",
    "        \n",
    "        print(subStart, subEnd)\n",
    "        assert np.array_equal(initStates[subStart : subEnd], states_stored_step0)\n",
    "        \n",
    "        with h5py.File(\"{0}/{1}/states_{2}_{3}/data_{0}_1_{2}.h5\".format(T, intervalRun, subStart, subEnd),\n",
    "                       \"r\") as fl:\n",
    "            FinStates_step1 = np.array(fl[\"FinalStates\"])\n",
    "            Disps_step1 = np.array(fl[\"SpecDisps\"])\n",
    "            times_step1 = np.array(fl[\"times\"])\n",
    "            allRates_step1 = np.array(fl[\"AllJumpRates\"])\n",
    "            allbarriers_step1 = np.array(fl[\"AllJumpBarriers\"])\n",
    "            rands_step1 = np.array(fl[\"TestRandNums\"])\n",
    "            JSelects_step1 = np.array(fl[\"JumpSelects\"])\n",
    "\n",
    "            ISEs_steps1 = np.array(fl[\"AllJumpISEnergy\"])\n",
    "            TSEs_steps1 = np.array(fl[\"AllJumpTSEnergy\"])\n",
    "            FSEs_steps1 = np.array(fl[\"AllJumpFSEnergy\"])\n",
    "\n",
    "        with h5py.File(\"{0}/{1}/states_{2}_{3}/data_{0}_2_{2}.h5\".format(T, intervalRun, subStart, subEnd),\n",
    "                       \"r\") as fl:\n",
    "            FinStates_step2 = np.array(fl[\"FinalStates\"])\n",
    "            Disps_step2 = np.array(fl[\"SpecDisps\"])\n",
    "            times_step2 = np.array(fl[\"times\"])\n",
    "            allRates_step2 = np.array(fl[\"AllJumpRates\"])\n",
    "            allbarriers_step2 = np.array(fl[\"AllJumpBarriers\"])\n",
    "            rands_step2 = np.array(fl[\"TestRandNums\"])\n",
    "            JSelects_step2 = np.array(fl[\"JumpSelects\"])\n",
    "\n",
    "            ISEs_steps2 = np.array(fl[\"AllJumpISEnergy\"])\n",
    "            TSEs_steps2 = np.array(fl[\"AllJumpTSEnergy\"])\n",
    "            FSEs_steps2 = np.array(fl[\"AllJumpFSEnergy\"])\n",
    "        \n",
    "        # store samples in necessary arrays\n",
    "        finalStates_UT[subStart : subEnd] = FinStates_step1[:]\n",
    "        \n",
    "        SpecDisps[subStart : subEnd, :, :] = Disps_step1[:]\n",
    "        SpecDisps_step2[subStart : subEnd, :, :] = Disps_step2[:]\n",
    "        \n",
    "        t_arr[subStart : subEnd] = times_step1[:]\n",
    "        t_arr_step2[subStart : subEnd] = times_step2[:]\n",
    "        \n",
    "        AllJumpRates_Init[subStart : subEnd] = allRates_step1[:]\n",
    "        AllJumpRates_Fin[subStart : subEnd] = allRates_step2[:]\n",
    "        \n",
    "        AllJumpBarriers_Init[subStart : subEnd] = allbarriers_step1[:]\n",
    "        AllJumpBarriers_Fin[subStart : subEnd] = allbarriers_step2[:]\n",
    "        \n",
    "        JumpSelects[subStart : subEnd] = JSelects_step1[:]\n",
    "        randomNumbers[subStart : subEnd] = rands_step1[:]\n",
    "        \n",
    "        JumpSelects_step2[subStart : subEnd] = JSelects_step2[:]\n",
    "        randomNumbers_step2[subStart : subEnd] = rands_step2[:]\n",
    "        \n",
    "        # Do some checks of detailed balance and site swapping and store the periodically translated states too\n",
    "        for samp in range(400):\n",
    "            init_stp1 = initStates[subStart + samp]\n",
    "            fin_stp1_UT = FinStates_step1[samp] # store the untranslated final state\n",
    "            stp1Select = JSelects_step1[samp]\n",
    "            fin_stp1 = init_stp1[JumpNewSites[stp1Select]] # store the periodically translated final state\n",
    "            finalStates[subStart + samp] = fin_stp1\n",
    "            \n",
    "            # check detailed balance\n",
    "            # get the transition state energy from the initial state\n",
    "            x1 = ISEs_steps1[samp, JSelects_step1[samp]] +\\\n",
    "            allbarriers_step1[samp, JSelects_step1[samp]]\n",
    "            \n",
    "            # get the transition state energy from the final state\n",
    "            inc = 1 if JSelects_step1[samp] % 2 == 0 else -1\n",
    "            x2 = ISEs_steps2[samp, JSelects_step1[samp] + inc] +\\\n",
    "            allbarriers_step2[samp, JSelects_step1[samp] + inc]\n",
    "            \n",
    "            # check that the two transition state energies are same within tolerance\n",
    "            assert np.allclose(x1, x2)\n",
    "            \n",
    "            # Check that the sites were swapped properly\n",
    "            stp1Select = JSelects_step1[samp]\n",
    "            stp2VacSite = NNsites_vac[stp1Select]\n",
    "            \n",
    "            dxStep1 = dxList[stp1Select]\n",
    "            dxStep1R, _ = superFCC.crys.cart2pos(dxStep1)\n",
    "            assert stp2VacSite == superFCC.index(dxStep1R, (0,0))[0]\n",
    "            \n",
    "            assert fin_stp1_UT[stp2VacSite] == 0\n",
    "            assert fin_stp1_UT[0] == init_stp1[stp2VacSite]\n",
    "            for siteInd in range(init_stp1.shape[0]):\n",
    "                if siteInd == 0 or siteInd == stp2VacSite:\n",
    "                    continue\n",
    "                else:\n",
    "                    assert fin_stp1_UT[siteInd] == init_stp1[siteInd]\n",
    "            \n",
    "            # Now for step 2\n",
    "            fin_stp2_UT = FinStates_step2[samp] # store the untranslated final state\n",
    "            \n",
    "            NNsites_vac_stp2 = NNsites[1:, stp2VacSite]\n",
    "            \n",
    "            stp2Select = JSelects_step2[samp]\n",
    "            stp3VacSite = NNsites_vac_stp2[stp2Select]\n",
    "            \n",
    "            dxStep2 = dxList[stp2Select]\n",
    "            dxStep2R = superFCC.crys.cart2pos(dxStep2)[0] + dxStep1R\n",
    "            assert stp3VacSite == superFCC.index(dxStep2R, (0,0))[0]\n",
    "            \n",
    "            assert fin_stp2_UT[stp3VacSite] == 0\n",
    "            assert fin_stp2_UT[stp2VacSite] == fin_stp1_UT[stp3VacSite]\n",
    "            \n",
    "            for siteInd in range(fin_stp1_UT.shape[0]):\n",
    "                if siteInd == stp2VacSite or siteInd == stp3VacSite:\n",
    "                    continue\n",
    "                else:\n",
    "                    assert fin_stp1_UT[siteInd] == fin_stp2_UT[siteInd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(AllJumpRates_Init, np.exp(- AllJumpBarriers_Init / (kB * T)))\n",
    "assert np.allclose(AllJumpRates_Fin, np.exp(- AllJumpBarriers_Fin / (kB * T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store a permutation sequence to mix up all the states later if needed and then split into training and testing\n",
    "perm = np.random.permutation(np.arange(initStates.shape[0]))\n",
    "\n",
    "# Save the extracted data in a suitable format for neural network and cluster expansion training\n",
    "with h5py.File(\"SingleStep_MEAM_{}_AllRates_2.h5\".format(T), \"w\") as fl:\n",
    "    fl.create_dataset(\"Permutation\", data=perm)\n",
    "    fl.create_dataset(\"InitStates\", data=initStates)\n",
    "    fl.create_dataset(\"FinStates\", data=finalStates)\n",
    "    fl.create_dataset(\"FinStates_UT\", data=finalStates_UT)\n",
    "    fl.create_dataset(\"SpecDisps\", data=SpecDisps)\n",
    "    fl.create_dataset(\"SpecDisps_step2\", data=SpecDisps_step2) # forgot to add this the first time\n",
    "    \n",
    "    fl.create_dataset(\"AllJumpRates_Init\", data=AllJumpRates_Init)\n",
    "    fl.create_dataset(\"AllJumpRates_Fin\", data=AllJumpRates_Fin)\n",
    "    fl.create_dataset(\"AllJumpBarriers_Init\", data=AllJumpBarriers_Init)\n",
    "    fl.create_dataset(\"AllJumpBarriers_Fin\", data=AllJumpBarriers_Fin)\n",
    "    fl.create_dataset(\"times\", data=t_arr)\n",
    "    fl.create_dataset(\"rates\", data=1./t_arr)\n",
    "    fl.create_dataset(\"times_step2\", data=t_arr_step2)\n",
    "    fl.create_dataset(\"rates_step2\", data=1./t_arr_step2)\n",
    "    \n",
    "    fl.create_dataset(\"JumpSelects\", data=JumpSelects)\n",
    "    fl.create_dataset(\"RandNums\", data=randomNumbers)\n",
    "    fl.create_dataset(\"JumpSelects_step2\", data=JumpSelects_step2)\n",
    "    fl.create_dataset(\"RandNums_step2\", data=randomNumbers_step2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
