{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "840c39a1",
   "metadata": {},
   "source": [
    "## Extracting and Storing States From Monte Carlo Runs\n",
    "In this notebook, we'll extract the staes (ASE supercells) stored with our Monte Carlo run (see \"job_script.sb\" for the example slurm job).\n",
    "\n",
    "We'll save our states into numpy arrays, which can then be used for initial states for Kinetic Monte Carlo calculations.\n",
    "\n",
    "Typically, as shown in our example job script, we do multiple Monte Carlo runs (also called Monte Carlo trajectories), each starting from an independent random state. Since the ultimate aim is to train machine learning models, we divide states from these trajectories equally into training and validation states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "716fe560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ase.spacegroup import crystal as crystal_ASE\n",
    "from ase.build import make_supercell\n",
    "import pickle\n",
    "from onsager import crystal, supercell\n",
    "import h5py\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd94b54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "elems = [\"Co\", \"Ni\", \"Cr\", \"Fe\", \"Mn\"]\n",
    "elemsToIndices = {\"Co\":0, \"Ni\":1, \"Cr\":2, \"Fe\":3, \"Mn\":4}\n",
    "elemsToNum = {}\n",
    "for elemInd, el in enumerate(elems):\n",
    "    elemsToNum[el] = elemInd + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5da4e774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Lattice:\n",
      "  a1 = [3.595 0.    0.   ]\n",
      "  a2 = [0.    3.595 0.   ]\n",
      "  a3 = [0.    0.    3.595]\n",
      "#Basis:\n",
      "  (A) 0.0 = [0. 0. 0.]\n",
      "  (A) 0.1 = [0.  0.5 0.5]\n",
      "  (A) 0.2 = [0.5 0.  0.5]\n",
      "  (A) 0.3 = [0.5 0.5 0. ]\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "# load crystal data for orthogonal FCC supercells\n",
    "N_units = 5\n",
    "with h5py.File(\"../../CrysDat_FCC/CrystData_ortho_{}_cube.h5\".format(N_units), \"r\") as fl:\n",
    "    lattice = np.array(fl[\"Lattice_basis_vectors\"])\n",
    "    superlatt = np.array(fl[\"SuperLatt\"])\n",
    "    basis_cubic = np.array(fl[\"basis_sites\"])\n",
    "\n",
    "a0=3.595\n",
    "crys = crystal.Crystal(lattice=lattice*a0, basis=[[b for b in basis_cubic]], chemistry=[\"A\"], noreduce=True)\n",
    "print(crys)\n",
    "\n",
    "superFCC_onsg = supercell.ClusterSupercell(crys, superlatt)\n",
    "print(len(superFCC_onsg.mobilepos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff8628b",
   "metadata": {},
   "source": [
    "## Now we go ahead and extract the states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d61a2a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_states(Temp, lowerTrajId, upperTrajId, startSamp, EndSamp, MC_interval, Nsites, a0=3.595):\n",
    "    \"\"\"\n",
    "    Function to extract ASE supercells, check them and store into numpy arrays.\n",
    "    :param: Temp - the temperature.\n",
    "    \n",
    "    For the following inputs, please also refer to example job script \"job_script.sb\" as well as the next\n",
    "    cell in this notebook.\n",
    "    \n",
    "    :param: lowerTrajId - the index of the first trajectory to gather states from.\n",
    "    :param: upperTrajId - the index of the last trajectory to gather states from.\n",
    "    \n",
    "    :param: startSamp - the MC step starting from which to gather states\n",
    "                        \n",
    "    :param: EndSamp - the last MC step.\n",
    "    \n",
    "    :param: MC_interval - the intervals at which to gather states.\n",
    "                          \n",
    "    :param: Nsites - the number of sites (512 in the example run).\n",
    "    \n",
    "    :param: a0: the lattice parameter (3.595 Angstroms)\n",
    "    \"\"\"\n",
    "    # initialize the state array\n",
    "    # Remember the supercells have had the (0., 0., 0.) site deleted for the vacancy\n",
    "    states = []\n",
    "    state_Energies = []\n",
    "    \n",
    "    total = 0\n",
    "    \n",
    "    # The \"jobID\" variable in the example script was set to 1\n",
    "    # In our actual runs, 4 more jobs with jobID = 2, 3, 4 and 5 were also run,\n",
    "    # each with atoms counts of Co, Ni, Cr, Fe and Mn as specified below\n",
    "    \n",
    "    count_1 = np.array([99, 100, 100, 100, 100]) # atom counts for jobID=1\n",
    "    count_2 = np.array([100, 99, 100, 100, 100]) # atom counts for jobID=2\n",
    "    count_3 = np.array([100, 100, 99, 100, 100]) # atom counts for jobID=3\n",
    "    count_4 = np.array([100, 100, 100, 99, 100]) # atom counts for jobID=4\n",
    "    count_5 = np.array([100, 100, 100, 100, 99]) # atom counts for jobID=5\n",
    "    \n",
    "    subJob = 1 # the \"jobID\" variable in the example script\n",
    "    # when extracting from 5 different jobs as mentioned above\n",
    "    # for subJob in range(1, 6):\n",
    "    print(\"Subjob: {}\".format(subJob), flush=True)\n",
    "    for traj in tqdm(range(lowerTrajId, upperTrajId + 1), ncols=65, position=0, leave=True):\n",
    "\n",
    "        dr = \"{0}_{1}/{0}_{1}_{2}/\".format(Temp,subJob,traj)\n",
    "        Run_Energies = np.load(\"{0}_{1}/{0}_{1}_{2}/Eng_all_steps.npy\".format(Temp,subJob,traj))\n",
    "\n",
    "        for samp in range(startSamp, EndSamp + 1, MC_interval):\n",
    "            \n",
    "            # get the saved supercell\n",
    "            fileName = dr+\"chkpt/supercell_{}.pkl\".format(samp)\n",
    "\n",
    "            with open(fileName, \"rb\") as fl:\n",
    "                superFCC = pickle.load(fl)\n",
    "\n",
    "            # check the supercell composition\n",
    "            elemCounts = np.zeros(len(elems), dtype=int)\n",
    "            for at_Ind in range(len(superFCC)):\n",
    "                elem = superFCC[at_Ind].symbol\n",
    "                idx = elemsToIndices[elem]\n",
    "                elemCounts[idx] += 1\n",
    "\n",
    "            if subJob == 1:\n",
    "                assert np.array_equal(elemCounts, count_1)\n",
    "\n",
    "            elif subJob == 2:\n",
    "                assert np.array_equal(elemCounts, count_2)\n",
    "\n",
    "            elif subJob == 3:\n",
    "                assert np.array_equal(elemCounts, count_3)\n",
    "\n",
    "            elif subJob == 4:\n",
    "                assert np.array_equal(elemCounts, count_4)\n",
    "\n",
    "            else:\n",
    "                assert np.array_equal(elemCounts, count_5)\n",
    "\n",
    "            # Check that the supercells are always consistent with onsager and store occupancies\n",
    "\n",
    "            assert np.allclose(superFCC.cell[:], superFCC_onsg.lattice)\n",
    "            assert np.allclose(superFCC.cell[:]/N_units, superFCC_onsg.crys.lattice)\n",
    "            assert len(superFCC) == Nsites - 1\n",
    "\n",
    "            occs = np.zeros(len(superFCC) + 1, dtype=np.int8)\n",
    "            for site in range(len(superFCC)):\n",
    "                assert not np.allclose(superFCC[site].position, 0.)\n",
    "                xs = superFCC[site].position\n",
    "                Rsite, ciSite = superFCC_onsg.crys.cart2pos(xs)\n",
    "                try:\n",
    "                    siteInd, _ = superFCC_onsg.index(Rsite, ciSite)\n",
    "                except:\n",
    "                    print(xs)\n",
    "                    raise ValueError(\"Site not found?\")\n",
    "                assert siteInd > 0\n",
    "                assert siteInd == superFCC[site].index + 1 == site + 1, \"{} {} {} {}\".format(Rs, Rsite, siteInd,\n",
    "                                                                              superFCC[site].index)\n",
    "                occs[site + 1] = elemsToNum[superFCC[site].symbol]\n",
    "\n",
    "            states.append(occs)\n",
    "            state_Energies.append(Run_Energies[samp])\n",
    "            total += 1\n",
    "                \n",
    "    print(\"Gathered total {} states from trajectories {} to {} \"\n",
    "          \"in each subjob 1 to 5.\".format(total, lowerTrajId, upperTrajId))\n",
    "    \n",
    "    return states, state_Energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76d8437c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T : 1073\n",
      "Subjob: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 20/20 [06:25<00:00, 19.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathered total 2000 states from trajectories 1 to 20 in each subjob 1 to 5.\n",
      "Subjob: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████| 20/20 [06:31<00:00, 19.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathered total 2000 states from trajectories 21 to 40 in each subjob 1 to 5.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Nsites = len(superFCC_onsg.mobilepos)\n",
    "\n",
    "T=1073\n",
    "print(\"T : {}\".format(T), flush=True)\n",
    "# Gather states from trajectories 1 to 20 for the training set\n",
    "states_1_to_20, Energies_1_to_20 = get_states(T, 1, 20, 10000, 10000 + 99 * 1000, 1000, Nsites)\n",
    "\n",
    "# Then from 21 to 40 for the validation set\n",
    "states_21_to_40, Energies_21_to_40 = get_states(T, 21, 40, 10000, 10000 + 99 * 1000, 1000, Nsites)\n",
    "print(\"\\n\\n\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f423be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then save as numpy files to use as initial states for KMC simulations\n",
    "\n",
    "states_1_to_20 = np.array(states_1_to_20, dtype=np.int8)\n",
    "states_21_to_40 = np.array(states_21_to_40, dtype=np.int8)\n",
    "\n",
    "Energies_1_to_20 = np.array(Energies_1_to_20)\n",
    "Energies_21_to_40 = np.array(Energies_21_to_40)\n",
    "\n",
    "assert states_1_to_20.shape[1] == states_21_to_40.shape[1] == len(superFCC_onsg.mobilepos)\n",
    "\n",
    "statesAll = np.zeros((states_1_to_20.shape[0] + states_21_to_40.shape[0],\n",
    "                      len(superFCC_onsg.mobilepos)), dtype=np.int8)\n",
    "\n",
    "EnergiesAll = np.zeros(states_1_to_20.shape[0] + states_21_to_40.shape[0])\n",
    "\n",
    "statesAll[:states_1_to_20.shape[0], :] = states_1_to_20[:, :]\n",
    "statesAll[states_1_to_20.shape[0]:, :] = states_21_to_40[:, :]\n",
    "\n",
    "EnergiesAll[:states_1_to_20.shape[0]] = Energies_1_to_20[:]\n",
    "EnergiesAll[states_1_to_20.shape[0]:] = Energies_21_to_40[:]\n",
    "\n",
    "assert np.all(statesAll[:, 0] == 0)\n",
    "\n",
    "np.save(\"statesAll_{}.npy\".format(T), statesAll)\n",
    "np.save(\"statesEnergies_CG_{}.npy\".format(T), EnergiesAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dceea9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
