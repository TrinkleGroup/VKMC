{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as pt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pickle\n",
    "from SymNet import SymNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "TestStates = np.load(\"TestStates.npy\")[:10]\n",
    "dxNN = np.load(\"nnJumpLatVecs.npy\")\n",
    "RtoSiteInd = np.load(\"RtoSiteInd.npy\")\n",
    "SiteIndtoR = np.load(\"SiteIndtoR.npy\")\n",
    "GpermNNIdx = np.load(\"GroupNNpermutations.npy\")\n",
    "\n",
    "NNsiteList = np.load(\"NNsites_sitewise.npy\")\n",
    "N_ngb = NNsiteList.shape[0]\n",
    "Nsites = NNsiteList.shape[1]\n",
    "with open(\"GroupOpsIndices.pkl\", \"rb\") as fl:\n",
    "    GIndtoGDict = pickle.load(fl)\n",
    "\n",
    "with open(\"supercellBCC.pkl\", \"rb\") as fl:\n",
    "    superBCC = pickle.load(fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 512)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_ngb, Nsites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "\n",
    "## First, we test for symmetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GnnPerms = pt.tensor(GpermNNIdx).long()\n",
    "NNsites = pt.tensor(NNsiteList)\n",
    "\n",
    "Nlayers = 1\n",
    "NchOuts = [1]\n",
    "\n",
    "Ng = GnnPerms.shape[0]\n",
    "Ndim = 3\n",
    "gdiags = pt.zeros(Ng*Ndim, Ng*Ndim).double()\n",
    "for gInd, g in GIndtoGDict.items():\n",
    "    rowStart = gInd * Ndim\n",
    "    rowEnd = (gInd + 1) * Ndim\n",
    "    gdiags[rowStart : rowEnd, rowStart : rowEnd] = pt.tensor(g.cartrot).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 512])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StateTensors = pt.tensor(TestStates/2.0).double().view(TestStates.shape[0], 1, TestStates.shape[1])\n",
    "N_batch = StateTensors.shape[0]\n",
    "StateTensors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's do backpropagation tests to make sure gradients are calculated correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a dummy loss function that tries to force\n",
    "# all vectors to -1\n",
    "def loss_fn(batchVecs):\n",
    "    N_batch = batchVecs.shape[0]\n",
    "    return pt.sum(pt.norm(batchVecs + pt.ones_like(batchVecs), dim=1)**2)/N_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now write an explicit convolution function\n",
    "# we'll test for a single sample: Input with batch size 1\n",
    "\n",
    "def conv(net, Input, layerInd, Filter, Gdict):\n",
    "    \n",
    "    weights = net.weightList[layerInd]\n",
    "    biasList = net.biasList[layerInd]\n",
    "    \n",
    "    Nsites = Input.shape[2]\n",
    "    \n",
    "    Out = pt.zeros(1, weights.shape[0], Nsites).double()\n",
    "    \n",
    "    for chOut in range(weights.shape[0]):\n",
    "        for siteInd in range(Nsites):\n",
    "            for gInd, g in Gdict.items():\n",
    "                Rsite = SiteIndtoR[siteInd]\n",
    "                sumSite = 0.\n",
    "                for chIn in range(weights.shape[1]):\n",
    "                    # permute the weights\n",
    "                    psi_perm = weights[ChOut, chIn][net.GnnPerms[gInd]]\n",
    "\n",
    "                    for ngb in range(1, net.N_ngb):\n",
    "                        dx = dxNN[ngb-1]\n",
    "                        Rngb = (Rsite + dx) % 8\n",
    "                        siteIndNgb = RtoSiteInd[Rngb[0], Rngb[1], Rngb[2]]\n",
    "                        \n",
    "                        sumSite += Input[0, chIn, siteIndNgb]*psi_perm[gnb]\n",
    "                    \n",
    "                    sumSite += Input[0, chIn, siteInd]*psi_perm[siteInd]\n",
    "                \n",
    "                sumSite += bias[chOut, 0]\n",
    "                Out[0, chOut, siteInd] += F.softplus(sumSite)\n",
    "    return Out/net.Ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestNet = SymNet(Nlayers, NchOuts, GnnPerms, GIndtoGDict, gdiags, NNsites, 3, active=\"relu\").double()\n",
    "optimizer = pt.optim.Adam(TestNet.parameters(), lr = 0.001)\n",
    "TestNet.RotateParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's first evaluate gradients with the network\n",
    "\n",
    "# We only use the first sample for now\n",
    "optimizer.zero_grad()\n",
    "InLayers, outlayersG, outlayers, outVecSites, out = TestNet.forward(StateTensors[0].view(-1, 1, 512),\n",
    "                                                                    Test=True)\n",
    "l = loss_fn(out)\n",
    "l.backward(retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4.2793e-15, 9.3221e-15, 1.9611e-15, 2.2934e-15, 2.0710e-15,\n",
       "          9.0832e-15, 4.1914e-15, 6.0701e-15, 2.2797e-16]]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestNet.weightList[0].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.4409e-16,  1.5543e-15, -1.9984e-15,  2.8866e-15, -1.9984e-15,\n",
       "          2.4425e-15, -3.3307e-15,  2.8866e-15, -4.6629e-15],\n",
       "        [-4.4409e-16,  1.9984e-15, -1.1102e-15, -3.3307e-15,  3.3307e-15,\n",
       "         -2.4425e-15,  1.5543e-15,  2.8866e-15, -2.4425e-15],\n",
       "        [ 4.4409e-16,  1.7764e-15, -2.6645e-15, -1.7764e-15,  2.6645e-15,\n",
       "          1.7764e-15, -3.1086e-15, -2.6645e-15,  3.1086e-15]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestNet.wtVC.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 512])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outVecSites.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumOutsLayer0 = outlayers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "yInd = 2\n",
    "k = 1\n",
    "yVecCart = np.dot(superBCC.crys.lattice, dxNN[yInd])\n",
    "siteVecs = pt.zeros(3, Nsites).double()\n",
    "siteGcomps = pt.zeros(Nsites, Ng, 3)\n",
    "\n",
    "for siteInd in range(Nsites):\n",
    "    \n",
    "    Rsite = SiteIndtoR[siteInd]\n",
    "    \n",
    "    sumg = pt.zeros(3).double()\n",
    "    \n",
    "    for gInd, g in GIndtoGDict.items():\n",
    "        \n",
    "        gTens = pt.tensor(g.cartrot).double()\n",
    "        \n",
    "        # Get the vector\n",
    "        gvec = pt.tensor([gTens[0, k], gTens[1, k], gTens[2, k]]).double()\n",
    "        \n",
    "        yvecCartG = np.dot(g.cartrot, yVecCart)\n",
    "        \n",
    "        yvecLat = np.dot(np.linalg.inv(superBCC.crys.lattice), yvecCartG).astype(int)\n",
    "        \n",
    "        RNew = (Rsite + yvecLat)%8\n",
    "        \n",
    "        siteNgb = RtoSiteInd[RNew[0], RNew[1], RNew[2]]\n",
    "        \n",
    "        s = sumOutsLayer0[0, 0, siteNgb]\n",
    "        \n",
    "        sumg += s*gvec\n",
    "    \n",
    "    siteVecs[:, siteInd] = sumg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2299, -0.1445,  0.4050,  ..., -0.0531, -0.4143,  0.0202],\n",
       "        [-0.2087, -0.0083,  0.0572,  ...,  0.0639, -0.5701,  0.0202],\n",
       "        [-0.0034,  0.3385, -0.3975,  ..., -0.0934,  0.2141,  0.3243]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "siteVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
