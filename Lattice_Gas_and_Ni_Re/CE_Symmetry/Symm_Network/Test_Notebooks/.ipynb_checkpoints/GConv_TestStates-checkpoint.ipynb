{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as pt\n",
    "import pickle\n",
    "from onsager import crystal, cluster, supercell\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "TestStates = np.load(\"../CrystalDat/TestStates.npy\")[:10]\n",
    "dxNN = np.load(\"../CrystalDat/nnJumpLatVecs.npy\")\n",
    "RtoSiteInd = np.load(\"../CrystalDat/RtoSiteInd.npy\")\n",
    "SiteIndtoR = np.load(\"../CrystalDat/SiteIndtoR.npy\")\n",
    "GpermNNIdx = np.load(\"../CrystalDat/GroupNNpermutations.npy\")\n",
    "\n",
    "NNsiteList = np.load(\"../CrystalDat/NNsites_sitewise.npy\")\n",
    "N_ngb = NNsiteList.shape[0]\n",
    "\n",
    "with open(\"../CrystalDat/GroupOpsIndices.pkl\", \"rb\") as fl:\n",
    "    GIndtoGDict = pickle.load(fl)\n",
    "\n",
    "with open(\"../CrystalDat/supercellBCC.pkl\", \"rb\") as fl:\n",
    "    superBCC = pickle.load(fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GpermNNIdx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expand the states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 512])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StateTensors = pt.tensor(TestStates/2.0).double().view(TestStates.shape[0], 1, TestStates.shape[1])\n",
    "StateTensors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 9, 512])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StateTensors_repeat = StateTensors.repeat_interleave(N_ngb, dim=1)\n",
    "StateTensors_repeat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, StateTensors.shape[0]):\n",
    "    for j in range(N_ngb):\n",
    "        assert pt.allclose(StateTensors[i, 0], StateTensors_repeat[i,j]), \"{} {}\".format(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, repeat the NNsites tensor\n",
    "NNsiteTensor = pt.tensor(NNsiteList).long()\n",
    "NNsitesBatchRepeat = NNsiteTensor.unsqueeze(0).repeat(StateTensors_repeat.shape[0],1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 512])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NNsiteTensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 9, 512])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NNsitesBatchRepeat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, StateTensors_repeat.shape[0]):\n",
    "    assert pt.equal(NNsiteTensor, NNsitesBatchRepeat[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 9, 512])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StatesTensorFull = pt.gather(StateTensors_repeat, 2, NNsitesBatchRepeat)\n",
    "StatesTensorFull.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stateInd in range(StateTensors.shape[0]):\n",
    "    stateFull = StatesTensorFull[stateInd]\n",
    "    for i in range(N_ngb):\n",
    "        indices=NNsiteTensor[i] # i^th nn site indices for all sites\n",
    "        nnSpecies = StateTensors[stateInd, 0][indices]\n",
    "        assert pt.equal(stateFull[i], nnSpecies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a random filter and test input image convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a randomized filter with Nch channels\n",
    "Nch = 4\n",
    "Psi = pt.rand(Nch, 1, N_ngb, requires_grad=True).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand the kernels by adding group permutations of nearest neighbor translations\n",
    "GnnPermTensor= pt.tensor(GpermNNIdx).long()\n",
    "Ng = GnnPermTensor.shape[0]\n",
    "\n",
    "# repeat the permutations Nch times for each channel\n",
    "GnnPermTensor_repeat = GnnPermTensor.repeat(Nch, 1).view(-1, 1, N_ngb)\n",
    "\n",
    "# Now repeat each filter channel Ng times and permute according to group ops\n",
    "Psi_repeat = Psi.repeat_interleave(Ng, dim=0)\n",
    "Psi_repeat_perm = pt.gather(Psi_repeat, 2, GnnPermTensor_repeat).view(-1, 1*N_ngb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([192, 9])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Psi_repeat_perm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the repeated kernels\n",
    "for ch in range(Nch):\n",
    "    FullPsiCh = Psi_repeat_perm[ch*Ng : (ch+1)*Ng]\n",
    "    for g in range(Ng):\n",
    "        Psiperm_g = Psi[ch,0][GnnPermTensor[g]]\n",
    "        assert pt.equal(FullPsiCh[g], Psiperm_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's do the bias terms\n",
    "bias = pt.rand(Nch).unsqueeze(1)\n",
    "bias_repeat = bias.repeat_interleave(Ng, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the convolution with the original state\n",
    "linOut = pt.matmul(Psi_repeat_perm, StatesTensorFull) + bias_repeat\n",
    "out = pt.nn.functional.softplus(linOut).view(StateTensors.shape[0], Nch, Ng, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 4, 48, 512])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "GtoGIndDict = {}\n",
    "for gInd, g in GIndtoGDict.items():\n",
    "    GtoGIndDict[g] = gInd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:05<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:05<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:05<00:00,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:05<00:00,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symmetry of 1st layer outputs correct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Multiply all Group ops with u^-1 and store new indices\n",
    "\n",
    "NtestSym = 5 #StateTensors.shape[0]\n",
    "for channel in range(Nch):\n",
    "    print(channel, flush=True)\n",
    "    out0 = out[0, channel]\n",
    "    for SampInd in tqdm(range(NtestSym), position=0, leave=True):\n",
    "        u = GIndtoGDict[SampInd]\n",
    "        uInv = u.inv()\n",
    "        outSamp = out[SampInd, channel]\n",
    "        out0Transf = pt.zeros(Ng, StateTensors.shape[2]).double()\n",
    "        for g, gInd in GtoGIndDict.items():\n",
    "            newGInd = GtoGIndDict[uInv*g]\n",
    "            for siteInd in range(StateTensors.shape[2]):\n",
    "                Rsite = SiteIndtoR[siteInd]\n",
    "                RsiteNew, _ = superBCC.crys.g_pos(uInv, Rsite, (0,0))\n",
    "                RsiteNew %= 8\n",
    "                siteIndNew = RtoSiteInd[RsiteNew[0], RsiteNew[1], RsiteNew[2]]\n",
    "\n",
    "                out0Transf[gInd, siteInd] = out0[newGInd, siteIndNew]\n",
    "                \n",
    "        assert pt.equal(outSamp, out0Transf), \"sample: {}, channel: {}\".format(SampInd, channel)\n",
    "        \n",
    "print(\"Symmetry of 1st layer outputs correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next, group averaging (pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "outSum = pt.sum(out, dim=2)/Ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group averaging correct\n"
     ]
    }
   ],
   "source": [
    "# Now for each state, check if the result is correct\n",
    "for sampInd in range(StateTensors.shape[0]):\n",
    "    for channel in range(Nch):\n",
    "        outSampChannel = out[sampInd, channel]\n",
    "        sumSamp = pt.zeros(outSum.shape[2]).double()\n",
    "        for i in range(Ng):\n",
    "            sumSamp += outSampChannel[i]\n",
    "        assert pt.allclose(sumSamp/Ng, outSum[sampInd, channel])\n",
    "print(\"Group averaging correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 4, 512])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outSum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symmetry of Group averaging correct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for sampInd in tqdm(range(StateTensors.shape[0]), position=0, leave=True):\n",
    "    g = GIndtoGDict[sampInd]\n",
    "    for channel in range(Nch):\n",
    "        # Now transform the original state's output  \n",
    "        out0New = pt.zeros(outSum.shape[2]).double()\n",
    "        for siteInd in range(out0New.shape[0]):\n",
    "            Rsite = SiteIndtoR[siteInd]\n",
    "            RsiteNew, _ = superBCC.crys.g_pos(g, Rsite, (0, 0))\n",
    "            RsiteNew %= 8 #apply PBC\n",
    "            siteIndNew = RtoSiteInd[RsiteNew[0], RsiteNew[1], RsiteNew[2]]\n",
    "            out0New[siteIndNew] = outSum[0, channel, siteInd].item()\n",
    "        \n",
    "        assert pt.allclose(out0New, outSum[sampInd, channel])\n",
    "\n",
    "print(\"Symmetry of Group averaging correct\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's first work out the kernel of the second layer\n",
    "### Input channels - Nch, ouput channels - Nch2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 9])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nch2 = 3 # Output of the layer will be 3 channels\n",
    "Psi2 = pt.rand(Nch2, Nch, N_ngb, requires_grad=True).double()\n",
    "Psi2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([144, 4, 9])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now rearrange the kernel into the full matrix correctly\n",
    "\n",
    "# First, let's do the repitition\n",
    "Psi2_repeat = Psi2.repeat_interleave(Ng, dim = 0)\n",
    "Psi2_repeat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we do the permutation\n",
    "GnnPermTensor_repeat_2 = GnnPermTensor.repeat(Nch2, Nch).view(-1, Nch, N_ngb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([144, 4, 9])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GnnPermTensor_repeat_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([48, 9])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GnnPermTensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "GnnPermTensor.repeat(Nch2, Nch)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GnnPermTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Psi2_repeat_perm = pt.gather(Psi2_repeat, 2, GnnPermTensor_repeat_2).view(-1, Nch*N_ngb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the repeated kernels again\n",
    "for ch2 in range(Nch2):\n",
    "    for ch1 in range(Nch):\n",
    "        # Get the portion of the kernel we need to test                \n",
    "        FullPsiCh2 = Psi2_repeat_perm[ch2*Ng : (ch2+1)*Ng, ch1*N_ngb:(ch1+1)*N_ngb]\n",
    "        for g in range(Ng):\n",
    "            Psi2perm_g = Psi2_repeat_perm[ch2*Ng, ch1*N_ngb:(ch1+1)*N_ngb][GnnPermTensor[g]]\n",
    "            assert pt.equal(FullPsiCh2[g], Psi2perm_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([144, 36])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Psi2_repeat_perm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1577, 0.5958, 0.1759, 0.9108, 0.3299, 0.5226, 0.6978, 0.6980, 0.9042,\n",
       "        0.3951, 0.1354, 0.4617, 0.6133, 0.8857, 0.5069, 0.4653, 0.7044, 0.2454,\n",
       "        0.8610, 0.8028, 0.2826, 0.4200, 0.4498, 0.4143, 0.0896, 0.4331, 0.0417,\n",
       "        0.8866, 0.7633, 0.7502, 0.6293, 0.4389, 0.7738, 0.7603, 0.2279, 0.4851],\n",
       "       dtype=torch.float64, grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Psi2_repeat_perm[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's do the bias terms\n",
    "bias2 = pt.rand(Nch2).unsqueeze(1)\n",
    "bias2_repeat = bias2.repeat_interleave(Ng, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next, we work out rearranging the output of the first layer into a suitable input for the second layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 4, 512])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outSum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 36, 512])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The channels are already stacked in outSum - so let's first repeat\n",
    "input2 = outSum\n",
    "input2_repeat = input2.repeat_interleave(N_ngb, dim=1)\n",
    "input2_repeat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 4, 512])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have to put in appropriate nearest neighbor sites\n",
    "NNbatchRepeatL2 = NNsiteTensor.unsqueeze(0).repeat(input2_repeat.shape[0], Nch, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 36, 512])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NNbatchRepeatL2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "input2_nnStack = pt.gather(input2_repeat, 2, NNbatchRepeatL2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 36, 512])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input2_nnStack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's see if nearest neighbors have been gathered properly\n",
    "for sampInd in range(StateTensors.shape[0]):\n",
    "    for ch in range(Nch):\n",
    "        inSampL2 = input2_nnStack[sampInd, ch*N_ngb : (ch+1)*N_ngb]\n",
    "        outSamp = outSum[sampInd, ch]\n",
    "        for ngb in range(N_ngb):\n",
    "            ngbSites = outSamp[NNsiteTensor[ngb]]\n",
    "            assert pt.equal(ngbSites, inSampL2[ngb]), \"{} {} {}\".format(sampInd, ch, ngb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's do the convolution\n",
    "out2 = pt.nn.functional.softplus(pt.matmul(Psi2_repeat_perm, input2_nnStack) + bias2_repeat).view(StateTensors.shape[0], Nch2,\n",
    "                                                        Ng, StateTensors.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 512])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now average group dimension again\n",
    "out2Sum = pt.sum(out2, dim=2)/Ng\n",
    "out2Sum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 15.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symmetry of layer 2 output correct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Now check symmetry\n",
    "for sampInd in tqdm(range(StateTensors.shape[0]), position=0, leave=True):\n",
    "    g = GIndtoGDict[sampInd]\n",
    "    for channel in range(Nch2):\n",
    "        # Now transform the original state's output  \n",
    "        out0New = pt.zeros(out2Sum.shape[2]).double()\n",
    "        for siteInd in range(out0New.shape[0]):\n",
    "            Rsite = SiteIndtoR[siteInd]\n",
    "            RsiteNew, _ = superBCC.crys.g_pos(g, Rsite, (0, 0))\n",
    "            RsiteNew %= 8 #apply PBC\n",
    "            siteIndNew = RtoSiteInd[RsiteNew[0], RsiteNew[1], RsiteNew[2]]\n",
    "            out0New[siteIndNew] = out2Sum[0, channel, siteInd].item()\n",
    "        \n",
    "        assert pt.allclose(out0New, out2Sum[sampInd, channel])\n",
    "\n",
    "print(\"Symmetry of layer 2 output correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 512])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2Sum.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's test R3 convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's make the kernel transformation matrix\n",
    "gdiags = pt.zeros(48*3, 48*3).double()\n",
    "for gInd, g in GIndtoGDict.items():\n",
    "    rowStart = gInd * 3\n",
    "    rowEnd = (gInd + 1) * 3\n",
    "    gdiags[rowStart : rowEnd, rowStart : rowEnd] = pt.tensor(g.cartrot).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's initialize the kernel\n",
    "Psi3 = pt.rand(3, N_ngb, requires_grad=True).double()\n",
    "\n",
    "# Repeat it\n",
    "Psi3_repeat = Psi3.repeat(Ng, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the permutations\n",
    "GnnPermTensor_R3_repeat = GnnPermTensor.repeat_interleave(3, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "Psi3_repeat_transf = pt.matmul(gdiags, pt.gather(Psi3_repeat, 1, GnnPermTensor_R3_repeat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now check if the transformations were correct\n",
    "Psi3_0 = Psi3\n",
    "for gInd, g in GIndtoGDict.items():\n",
    "    cartRotTens = pt.tensor(g.cartrot).double()\n",
    "    Psi3_g = Psi3_repeat_transf[gInd*3 : (gInd+1)*3, :]\n",
    "    for nn in range(N_ngb):\n",
    "        nnPerm = GnnPermTensor[gInd, nn]\n",
    "        if nn == 0: # the on-site term should only be rotated\n",
    "            assert nnPerm == 0        \n",
    "        # The rest of the NNs should be permuted and rotated\n",
    "        assert pt.allclose(pt.matmul(cartRotTens, Psi3_0[:, nnPerm]), Psi3_g[:, nn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 9]), torch.Size([3, 9]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Psi3.shape, Psi3_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 512])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For the output, we only select the 0-channel result of out2Sum\n",
    "out2Sum.shape\n",
    "Inps3 = out2Sum[:, 0, :].view(StateTensors.shape[0], 1, StateTensors.shape[2])\n",
    "Inps3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 9, 512])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next, repeat and arrange input sites with neareset neighbors\n",
    "Inps3_repeat = Inps3.repeat_interleave(N_ngb, dim=1)\n",
    "Inps3_repeat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inps3_nn = pt.gather(Inps3_repeat, 2, NNsitesBatchRepeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 9, 512])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Inps3_nn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([144, 9])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Psi3_repeat_transf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "Outs3 = pt.matmul(Psi3_repeat_transf, Inps3_nn).view(StateTensors.shape[0], Ng, 3, StateTensors.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs3GSum = pt.sum(Outs3, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 512])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs3GSum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 14.60it/s]\n"
     ]
    }
   ],
   "source": [
    "# Check if for rotated states, vectors have also been rotated correctly\n",
    "out3_0 = outs3GSum[0]\n",
    "count = 0\n",
    "for sampInd in tqdm(range(StateTensors.shape[0]), position=0, leave=True):\n",
    "    g = GIndtoGDict[sampInd]\n",
    "    gTens = pt.tensor(g.cartrot).double()\n",
    "    for siteInd in range(StateTensors.shape[2]):\n",
    "        # Get the vector at this site for state 0\n",
    "        vecSite0 = out3_0[:, siteInd]\n",
    "        \n",
    "        # Rotate the vector\n",
    "        vecNew = pt.matmul(gTens, vecSite0)\n",
    "        \n",
    "        # Now get the transformed site\n",
    "        Rsite = SiteIndtoR[siteInd]\n",
    "        Rnew, _ = superBCC.crys.g_pos(g, Rsite, (0, 0))\n",
    "        Rnew %= 8\n",
    "        siteIndNew = RtoSiteInd[Rnew[0], Rnew[1], Rnew[2]]\n",
    "        \n",
    "        assert pt.allclose(vecNew, outs3GSum[sampInd, :, siteIndNew])\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5120"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs3SiteSum = pt.sum(outs3GSum, dim=2)\n",
    "outs3SiteSum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.9581e-13,  2.0464e-12,  0.0000e+00],\n",
       "        [ 6.7075e-12,  4.5475e-13, -2.8990e-12],\n",
       "        [ 1.1937e-12, -9.0949e-13, -4.2064e-12],\n",
       "        [ 1.3358e-12, -1.7906e-12, -2.4443e-12],\n",
       "        [-1.9895e-12, -1.5916e-12, -1.7621e-12],\n",
       "        [-4.6043e-12,  5.6843e-14, -2.4443e-12],\n",
       "        [ 1.4779e-12,  4.5475e-13,  3.0695e-12],\n",
       "        [ 1.2790e-12, -1.4921e-12, -1.0800e-12],\n",
       "        [-3.4674e-12,  6.2528e-13, -2.7853e-12],\n",
       "        [-3.0695e-12, -2.2737e-12, -1.9895e-12]], dtype=torch.float64,\n",
       "       grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs3SiteSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73, 511)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RtoSiteInd[1,1,1], RtoSiteInd[-1,-1,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 50.1469, -59.5655, -22.8830], dtype=torch.float64,\n",
       "        grad_fn=<SelectBackward>),\n",
       " tensor([ 38.6426, -12.0880,  -7.6604], dtype=torch.float64,\n",
       "        grad_fn=<SelectBackward>))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs3GSum[0,:,RtoSiteInd[1,1,1]], outs3GSum[0,:,RtoSiteInd[-1,-1,-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5011e-12, dtype=torch.float64, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.sum(outs3GSum[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 512])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs3GSum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "out30 = outs3GSum[0, :, RtoSiteInd[1,1,1]]\n",
    "sites = {}\n",
    "for siteInd1 in range(outs3GSum.shape[2]):\n",
    "    vec1 = outs3GSum[0, :, siteInd1]\n",
    "    sites[siteInd1] = []\n",
    "    for siteInd2 in range(outs3GSum.shape[2]):\n",
    "        vec2 = outs3GSum[0, :, siteInd2]\n",
    "        if pt.allclose(vec1+vec2, pt.zeros_like(vec1).double()):\n",
    "            sites[siteInd1].append(siteInd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
